---
{"dg-publish":true,"permalink":"/readwise/books/super-thinking/"}
---

# Super Thinking

![rw-book-cover](https://readwise-assets.s3.amazonaws.com/static/images/default-book-icon-7.09749d3efd49.png)

## Metadata
- Date: [[Calendar/<%tp.date.now("DD-MM-YYYY")%>\|Calendar/<%tp.date.now("DD-MM-YYYY")%>]]
- Author: [[Gabriel Weinberg\|Gabriel Weinberg]]
- Full Title: Super Thinking
- Category: #books

## Highlights
- super models are shortcuts to higher-level thinking. If you can understand the relevant models for a situation, then you can bypass lower-level thinking and immediately jump to higher-level thinking. In contrast, people who don’t know these models will likely never reach this higher level, and certainly not quickly.
    - Note: Cosa sono i super models? Si tratta di [[Mental Models\|Mental Models]] che possono essere astratti dal loro dominio specifico ed utilizzati in tutti gli altri domini del ragionamento.
      All’atto pratico sono dele scorciatoie che possiamo utilizzare per raggiungere un livello più profondo di ragionamento ed arrivare a soluzioni più elaborate e basate su background che non abbiamo raggiunto autonomamente ma che è già definito in precedenza.
- The central mental model to help you become a chef with your thinking is arguing from first principles. It’s the practical starting point to being wrong less, and it means thinking from the bottom up, using basic building blocks of what you think is true to build sound (and sometimes new) conclusions. First principles are the group of self-evident assumptions that make up the foundation on which your conclusions rest—the ingredients in a recipe or the mathematical axioms that underpin a formula.
- Any problem can be approached from first principles. Take your next career move. Most people looking for work will apply to too many jobs and take the first job that is offered to them, which is likely not the optimal choice. When using first principles, you’ll instead begin by thinking about what you truly value in a career (e.g., autonomy, status, mission, etc.), your required job parameters (financial, location, title, etc.), and your previous experience. When you add those up, you will get a much better picture of what might work best for your next career move, and then you can actively seek that out.
    - Note: Come si può applicare il [[Mental Models\|Mental Models]] del [[first principle thinking\|first principle thinking]] alle proprie scelte di carriera?
      Si può applicare ragionando in maniera deterministica a partire da ciò che sappiamo di volere.
      Determinando, infatti, i fattori che più sappiamo ci renderanno felici sul posto di lavoro, quelli per noi determinanti (stipendio, ruolo, smart working ecc.) potremo facilmente filtrare offerte di lavoro ed indirizzare il nostro invio di candidature.
- to be wrong less, you also need to be testing your assumptions in the real world, a process known as de-risking. There is risk that one or more of your assumptions are untrue, and so the conclusions you reach could also be false.
    - Note: Quale [[Mental Models\|Mental Models]] meglio ci permette di rendere pratico il [[first principle thinking\|first principle thinking]] ?
      Si tratta del modello del [[de-risking\|de-risking]] , un modello che mira a verificare che le ipotesi che facciamo riguardo una questione siano vere oppure no.
      Se tali ipotesi dovessero essere false infatti, allora anche le conclusioni a cui giungeremmo (tramite first principle) sarebbero errate. È necessario quindi prima validarle.
- Once you get specific enough with your assumptions, then you can devise a plan to test (de-risk) them. The most important assumptions to de-risk first are the ones that are necessary conditions for success and that you are most uncertain about. For example, in the startup context, take the assumption that your solution sufficiently solves the problem it was designed to solve. If this assumption is untrue, then you will need to change what you are doing immediately before you can proceed any further, because the whole endeavor won’t work otherwise. Once you identify the critical assumptions to de-risk, the next step is actually going out and testing these assumptions, proving or disproving them, and then adjusting your strategy appropriately.
    - Note: In che cosa consiste, precisamente, il [[Mental Models\|Mental Models]] del [[de-risking\|de-risking]] ?
      In che modo si collega col concetto di #validazione ?
      Il concetto di de-risking è essenzialmente il concetto di validazione delle ipotesi che facciamo.
      Proprio tramite questo concetto di validazione si può avere la certezza che le nostre ipotesi siano reali e che quindi porteranno a conclusioni esatte (e quindi sbagliamo di meno).
      Quando si parla di de-risking, o validazione, allora è importante seguire alcuni passi:
      - prendere le ipotesi che abbiamo deciso di voler verificare e spacchettiamole, riduciamole in ipotesi più piccole ed elementari, più facili da verificare,
      - una volta spacchettate tutte le ipotesi dobbiamo decidere quali sono quelle più essenziali da verificare, quelle la cui verità o falsità possono avere influenza sulla verità o falsità dell’intera conclusione
- Back in startup land, there is another mental model to help you test your assumptions, called minimum viable product, or MVP. The MVP is the product you are developing with just enough features, the minimum amount, to be feasibly, or viably, tested by real people.
    - Note: In che modo il [[Mental Models\|Mental Models]] del [[de-risking\|de-risking]] si declina nel mondo del coding e delle startup?
      Nel mondo del coding il modello del de-risking permette di evitare il problema della [[premature optimization\|premature optimization]] quella situazione in cui ci si ritrova quando si ottimizza, migliora e si investe ulteriore tempo su un codice la cui funzionalità ed utilità generale ancora non si è verificata.
      Nel mondo delle startup, invece, il modello del [[de-risking\|de-risking]] si declina nel concetto di [[MVP\|MVP]]
      Con [[MVP\|MVP]] infatti si intende creare qualcosa col minimo sforzo di tempo e di impegno ma con le caratteristiche essenziali da testare e poi testarlo in maniera da avviare il prima possibile lo scambio col contesto che davvero rende migliore ed utile un prodotto.
- Ockham’s razor helps here. It advises that the simplest explanation is most likely to be true. When you encounter competing explanations that plausibly explain a set of data equally well, you probably want to choose the simplest one to investigate first.
    - Note: In cosa consiste il [[Mental Models\|Mental Models]] del [[rasoio di occam\|rasoio di occam]] ?
      Consiste che a parità di condizioni la migliore soluzione ad un problema, molto probabilmente è quella più semplice
- If you don’t simplify your assumptions, you can fall into a couple of traps, described in our next mental models. First, most people are, unfortunately, hardwired to latch onto unnecessary assumptions, a predilection called the conjunction fallacy,
    - Note: Cosa può accadere se non si semplificano le proprie ipotesi ?
      Può succedere che cadiamo nel caso della [[fallacia della congiunzione\|fallacia della congiunzione]]
- The fallacy arises because the probability of two events in conjunction is always less than or equal to the probability of either one of the events occurring alone,
    - Note: Cosa afferma la [[fallacia della congiunzione\|fallacia della congiunzione]] ?
      Questa fallacia mette in evidenza come abbiamo la tendenza naturale a pensare che la probabilità del verificarsi di due eventi in congiunzione sia maggiore di quella del verificarsi di uno solo di questi eventi
- Overfitting occurs when you use an overly complicated explanation when a simpler one will do. It’s what happens when you don’t heed Ockham’s razor, when you get sucked into the conjunction fallacy or make a similar unforced error. It can occur in any situation where an explanation introduces unnecessary assumptions.
    - Note: In cosa consiste la trappola dell’ [[overfitting\|overfitting]] ?
- When crafting a solution to a problem, whether making a decision or explaining data, you want to start with the simplest set of assumptions you can think of and de-risk them as simply as possible.
    - Note: Quale è il consiglio migliore per evitare le trappole di ragionamento della [[fallacia della congiunzione\|fallacia della congiunzione]] e dell’ [[overfitting\|overfitting]] ? 
      È quello di rendere tutto semplice, non balzare a supposizioni elaborate o aggiungere conclusioni senza prova, semplificare il più possibile le proprie ipotesi e poi provvedere al [[de-risking\|de-risking]]
- 
- If you’re trying to be as objective as possible when making a decision or solving a problem, you always want to account for your frame of reference. You will of course be influenced by your perspective, but you don’t want to be unknowingly influenced. And if you think you may not have the full understanding of a situation, then you must actively try to get it by looking from a variety of different frames of reference.
    - Note: Cosa è importante considerare quando ci cerca di prendere una decisione dal punto di vista oggettivo?
      È importante considerare il [[frame of reference\|frame of reference]] da cui stiamo valutando le cos’è, in funzione di questo tutte le informazioni a nostra disposizione possono cambiare.
      È importante cercare di valutare tutti i [[frame of reference\|frame of reference]] perché questa cosa influenza in maniera inevitabile, il minimo che possiamo fare è lasciarci influenzare in maniera consapevole.
- Framing refers to the way you present a situation or explanation. When you present an important issue to your coworker or family member, you try to frame it in a way that might help them best understand your perspective, setting the stage for a beneficial conversation.
    - Note: In cosa consiste il [[framing\|framing]] ?
      Consiste nel presentare una situazione, idea, decisione utilizzando il [[frame of reference\|frame of reference]] che più ci permette di avere risultati positivi.
- When someone presents a new idea or decision to you, take a step back and consider other ways in which it could be framed.
    - Note: Riuscire a valutare ogni [[frame of reference\|frame of reference]] quando si prende una decisione cosa ci permette di evitare ?
      Ci permette di evitare la trappola di un [[framing\|framing]] utilizzato a nostro danno
- You can be nudged in a direction by a subtle word choice or other environmental cues. Restaurants will nudge you by highlighting certain dishes on menu inserts, by having servers verbally describe specials, or by just putting boxes around certain items. Retail stores and websites nudge you to purchase certain products by placing them where they are easier to see.
    - Note: Quali possono essere alcuni esempi di [[nudge\|nudge]] ?
- anchoring, which describes your tendency to rely too heavily on first impressions when making decisions. You get anchored to the first piece of framing information you encounter.
    - Note: In cosa consiste la trappola dell’ [[anchoring\|anchoring]] consiste nel fatto che siamo soliti prendere decisioni in funzione della prima che ci viene presentata
- Readers were offered three ways to subscribe: web only ($59), print only ($125), and print and web ($125). Yes, you read that right: the “print only” version cost the same as the “print and web” version. Who would choose that? Predictably, no one. Here is the result when one hundred MIT students reported their preference: Web only ($59): 16 percent Print only ($125): 0 percent Print and web ($125): 84 percent So why include that option at all? Here’s why: when it was removed from the question, this result was revealed: Web only ($59): 68 percent Print and web ($125): 32 percent Just having the print-only option—even though no one chooses it—anchors readers to a much higher value for the print-and-web version. It feels like you are getting the web version for free, causing many more people to choose it and creating 43 percent more revenue for the magazine by just adding a version that no one chooses!
    - Tags: [[blu\|blu]] 
    - Note: Quale può essere un esempio di [[anchoring\|anchoring]] applicato alla vendita?
- Trump uses this mental model, anchoring others to his extreme positions, so that what seem like compromises are actually agreements in his favor. He wrote about this in his 1987 book Trump: The Art of the Deal: My style of deal-making is quite simple and straightforward. I aim very high, and then I just keep pushing and pushing to get what I’m after. Sometimes I settle for less than I sought, but in most cases I still end up with what I want.
    - Tags: [[blu\|blu]] 
- these mental models are all instances of a more general model, availability bias, which occurs when a bias, or distortion, creeps into your objective view of reality thanks to information recently made available to you.
    - Note: In quale [[mental models\|mental models]] rientrano i vari casi di [[framing\|framing]] e [[anchoring\|anchoring]] ?
      Rientrano nei casi del [[bias della disponibilità\|bias della disponibilità]] che è quel bias per cui tendiamo a prendere decisioni errate in funzione delle informazioni che abbiamo più a disposizione.
- Let’s say you are a manager and you need to write an annual review for your direct report. You are supposed to think critically and objectively about her performance over the entire year. However, it’s easy to be swayed by those really bad or really good contributions over just the past few weeks. Or you might just consider the interactions you have had with her personally, as opposed to getting a more holistic view based on interactions with other colleagues with different frames of reference.
    - Tags: [[blu\|blu]] 
- When you put many similar filter bubbles together, you get echo chambers, where the same ideas seem to bounce around the same groups of people, echoing around the collective chambers of these connected filter bubbles. Echo chambers result in increased partisanship, as people have less and less exposure to alternative viewpoints.
    - Note: Cosa accade quando metti in sequenza diversa [[filter bubbles\|filter bubbles]] ? Accade che si genera una [[echo chambers\|echo chambers]] in cui l’idea che emerge da una di queste bubble rimbalza, rimbalza e rimbalza, ogni volta rafforzandosi e ci si ritrova sempre meno esposti a prospettive alternative e sempre più radicalizzati
- to be wrong less when thinking about people, you must find ways to increase your empathy, opening up a deeper understanding of what other people are really thinking.
- In any conflict between two people, there are two sides of the story. Then there is the third story, the story that a third, impartial observer would recount. Forcing yourself to think as an impartial observer can help you in any conflict situation,
- Authors Douglas Stone, Bruce Patton, and Sheila Heen explore this model in detail in their book Difficult Conversations: “The key is learning to describe the gap—or difference—between your story and the other person’s story. Whatever else you may think and feel, you can at least agree that you and the other person see things differently.” If you can coherently articulate other points of view, even those directly in conflict with your own, then you will be less likely to make biased or incorrect judgments.
    - Note: Come si può fare in modo di aprirsi il più possibile alla visione di un terzo elemento esterno ed oggettivo tra due che litigano ?
      Si può riuscire a fare una cosa del genere cercando di capire così in profondità la narrativa dell’altra persona da riuscire a descriverla e raccontarla in dettaglio, come se fosse la nostra.
      Ci si riferisce a questa tattica come quella del [[terzo osservatore\|terzo osservatore]]
- Another tactical model that can help you empathize is the most respectful interpretation, or MRI. In any situation, you can explain a person’s behavior in many ways. MRI asks you to you interpret the other parties’ actions in the most respectful way possible. It’s giving people the benefit of the doubt.
    - Note: In cosa consiste la tattica del [[MRI\|MRI]] ?
      Consiste nel descrivere ed interpretare le azioni dell’altra persona nella maniera più rispettosa possibile, nel dare agli altri il beneficio del dubbio
- The point is you don’t know the real answer yet, but if you approach the situation with the most respectful interpretation, then you will generally build trust with those involved rather than destroy it. With MRI, your follow-up email or call is more likely to have an inquisitive tone rather than an accusatory one. Building trust pays dividends over time, especially in difficult situations where that trust can serve as a bridge toward an amicable resolution. The next time you feel inclined to make an accusation, take a step back and think about whether that is really a fair assumption to make.
    - Note: Quale è il vantaggio di usare tattiche e modelli come quella di [[MRI\|MRI]] ?
      Il vantaggio è quello di indirizzare i prossimi scambi verso un’atmosfera di fiducia che getta le basi poi di una relazione positiva invece che partire con la caccia alle streghe.
- Another way of giving people the benefit of the doubt for their behavior is called Hanlon’s razor: never attribute to malice that which is adequately explained by carelessness. Like Ockham’s razor, Hanlon’s razor seeks out the simplest explanation.
- And when people do something harmful, the simplest explanation is usually that they took the path of least resistance.
    - Note: Come si declina la tattica del [[rasoio di Hanlon\|rasoio di Hanlon]] quando si verificano dei danno sostanziali?
      La spiegazione più semplice in questo caso è che hanno scelto la strada più pigra.
- Hanlon’s razor is especially useful for navigating connections in the virtual world.
    - Note: Quale è il contesto in cui più può essere utile applicare il [[rasoio di Hanlon\|rasoio di Hanlon]] ?
- the fundamental attribution error, where you frequently make errors by attributing others’ behaviors to their internal, or fundamental, motivations rather than external factors. You are guilty of the fundamental attribution error whenever you think someone was mean because she is mean rather than thinking she was just having a bad day.
    - Note: Le tre tattiche di [[MRI\|MRI]], [[rasoio di Hanlon\|rasoio di Hanlon]] e quella del colmare la lacuna, quale grande errore psicologico che compiamo cercano di risolvere ? 
      Quello dell’ [[errore fondamentale di attribuzione\|errore fondamentale di attribuzione]], che afferma ?
      Afferma che noi tendiamo ad attribuire a cause interne le azioni degli altri, quando invece potrebbero (e magari sono) semplicemente attribuibili a fattori esterni
- When you are the actor, you often have self-serving reasons for your behavior, but when you are the observer, you tend to blame the other’s intrinsic nature. (That’s why this model is also sometimes called actor-observer bias.)
    - Note: Quale é a prospettiva inversa allerrore di attribuzione fondamentale?
      È quello che riguarda noi ed il fatto che quando siamo noi gli attori della narrazione allora le cause dei nostri errori dipendono da fattori esterni
- when thinking about how society should be organized, we should do so by imagining ourselves ignorant of our particular place in the world, as if there were a veil preventing us from knowing who we are. Rawls refers to this as the “original position.” For example, you should not just consider your current position as a free person when contemplating a world where slavery is allowed. You must consider the possibility that you might have been born a slave, and how that would feel. Or, when considering policies regarding refugees, you must consider the possibility that you could have been one of those seeking refuge. The veil of ignorance encourages you to empathize with people across a variety of circumstances, so that you can make better moral judgments.
    - Note: Qule altro modello tattico possiamo utilizzare per avere maggiore empatia?
- It can be challenging to acknowledge that a good portion of your success stems from luck. Many people instead choose to believe that the world is completely fair, orderly, and predictable. This view is called the just world hypothesis, where people always get what they deserve, good or bad, because of their actions alone, with no accounting for luck or randomness. This view is summed up as you reap what you sow. Ironically, belief in a just world can get in the way of actual justice by leading people to victim-blame: The sexual assault victim “should have worn different clothes” or the welfare recipient “is just lazy.” Victims of circumstance are actually blamed for their circumstances, with no accounting for factors of randomness like the birth lottery.
    - Note: In quale tipologia di [[mental model\|mental model]] si ritrova chi pensa che il mondo garantisca a tutti quelli che meritano e per cui lavorano?
      Ricadono nella situazione del [[mondo giusto\|mondo giusto]] un modo di pensare che poi facilmente porta alla fallacia della [[vittimizzazione\|vittimizzazione]]
- Learned helplessness describes the tendency to stop trying to escape difficult situations because we have gotten used to difficult conditions over time. Someone learns that they are helpless to control their circumstances, so they give up trying to change them.
    - Note: Quale altro [[mental model\|mental model]] porta le persone a pensare che nulla possano fare per fuggire da situazioni che non gli piacciono o comunque disagiate ?
- Learned helplessness can be overcome when animals or people see that their actions can make a difference, that they aren’t actually helpless. A shining light in the reduction of chronic homelessness has been a strategy that directly combats learned helplessness, helping people take back control of their lives after years on the streets. The strategy, known as Housing First, involves giving apartments to the chronic homeless and, at the same time, assigning a social worker to help each person reintegrate into society, including finding work and living day-to-day in their apartment.
    - Note: In che modo si può aiutare le persone ad uscire dal [[mental model\|mental model]] del [[condizionamento alla resa\|condizionamento alla resa]]? 
      Mostrando a queste persone come il loro agire può fare la differenza
- Just as you can be anchored to a price, you can also be anchored to an entire way of thinking about something. In other words, it can be very difficult to convince you of a new idea when a contradictory idea is already entrenched in your thinking.
- paradigm shift model, describing how accepted scientific theories change over time.
    - Note: Cosa descrive il [[mental model\|mental model]] del [[cambio di paradigma\|cambio di paradigma]] ?
      Descrive il modo in cui le teorie scientifiche cambiano nel corso del tempo, arrivando al punto in cui alcune si sovvertono totalmente.
      Il cambiamento in questione avviene in questo modo: per x tempo la teoria scientifica risulta incontestabile ed inattaccabile, ogni opposizione ad essa viene taciuta o messa da parte.
      Col tempo queste teorie in opposizione (ed i problemi che evidenziano nella teoria principale) si ammassano tra loro, quasi una sull’ altra, fino ad arrivare al punto in cui raggiungono la massa critica e l’ arrivo di una nuova teoria scientifica in opposizione fa traboccare il vaso.
- Max Planck explained it like this in his Scientific Autobiography and Other Papers: “A new scientific truth does not triumph by convincing its opponents and making them see the light, but rather because its opponents eventually die, and a new generation grows up that is familiar with it,” or, more succinctly, “Science progresses one funeral at a time.”
- However, they both noticed obvious and important empirical truths that should have been investigated by other scientists but were reflexively rejected by these scientists because the suggested explanations were not in line with the conventional thinking of the time. Today, this is known as a Semmelweis reflex.
    - Note: In cosa consiste il [[riflesso di semmelweiss\|riflesso di semmelweiss]] ?
      Consiste nell’istinto (riflesso) con cui gli scienziati sono soliti rifiutare le teorie ed ipotesi empiriche e che vadano in contrasto con quanto affermato da una teoria principale.
- The human tendency to gather and interpret new information in a biased way to confirm preexisting beliefs is called confirmation bias.
    - Note: A quale tipo di bias si possono ricollegare il [[riflesso di semmelweiss\|riflesso di semmelweiss]] e tutto il percorso che porta al [[cambiamento di paradigma\|cambiamento di paradigma]] ?
      Si collegano al [[bias della conferma\|bias della conferma]] che indica come gli umani siano soliti interpretare le nuove informazioni in maniera tale da confermare i loro modelli preesistenti della realtà, in pratica qualcosa che confermi le loro convinzioni e non le metta in dubbio.
- Confirmation bias is so hard to overcome that there is a related model called the backfire effect that describes the phenomenon of digging in further on a position when faced with clear evidence that disproves it. In other words, it often backfires when people try to change your mind with facts and figures, having the opposite effect on you than it should; you become more entrenched in the original, incorrect position, not less.
    - Note: Il [[confirmation bias\|confirmation bias]] è così radicato in noi che ci porta a rispondere quando ci vengono presentati in maniera oggettiva dei fatti che vanno in contrasto con le nostre vedute?
      Tramite il [[backfire effect\|backfire effect]] con cui tendiamo a radicalizzarci nelle nostre idee una volta che ci espongono i fatti che dimostrano la loro inesattezza.
- You may also succumb to holding on to incorrect beliefs because of disconfirmation bias, where you impose a stronger burden of proof on the ideas you don’t want to believe.
    - Note: Quale è il bias opposto al [[bias della conferma\|bias della conferma]] ma che danneggia in egual modo la nostra capacità di interpretare i fatti?
      Si tratta del [[disconfermation bias\|disconfermation bias]] che indica proprio come tendiamo a imporre modi più rigorosi e forti di verifica ed indagine a quei fatti che non ci piacciono (e che magari vanno in contrasto con la nostra precedente interpretazione della realtà).
- The pernicious effects of confirmation bias and related models can be explained by cognitive dissonance, the stress felt by holding two contradictory, dissonant, beliefs at once. Scientists have actually linked cognitive dissonance to a physical area in the brain that plays a role in helping you avoid aversive outcomes. Instead of dealing with the underlying cause of this stress—the fact that we might actually be wrong—we take the easy way out and rationalize the conflicting information away. It’s a survival instinct!
    - Note: Il [[confirmation bias\|confirmation bias]] ed il [[disconfermation bias\|disconfermation bias]] a quale più grande modello si ispirano? A quello della [[dissonanza cognitiva\|dissonanza cognitiva]] che indica la nostra incapacità di poter gestire due interpretazioni della realtà che siano in contrapposizione.
      Si tratta di un istinto di conservazione (e sopravvivenza) che ci porta a gestire lo stress che deriva dalle due interpretazioni delle realtà in contrasto. Gestiamo questo stress mettendo da parte la nuova interpretazione e razionalizzandola tramite uno dei due bias che abbiamo indicato.
- thinking gray, a concept we learned from Steven Sample’s book The Contrarian’s Guide to Leadership. You may think about issues in terms of black and white, but the truth is somewhere in between, a shade of gray. As Sample puts it: Most people are binary and instant in their judgments; that is, they immediately categorize things as good or bad, true or false, black or white, friend or foe. A truly effective leader, however, needs to be able to see the shades of gray inherent in a situation in order to make wise decisions as to how to proceed. The essence of thinking gray is this: don’t form an opinion about an important matter until you’ve heard all the relevant facts and arguments, or until circumstances force you to form an opinion without recourse to all the facts (which happens occasionally, but much less frequently than one might imagine). F. Scott Fitzgerald once described something similar to thinking gray when he observed that the test of a first-rate mind is the ability to hold two opposing thoughts at the same time while still retaining the ability to function.
    - Note: Quale [[mental model\|mental model]] può aiutarci a resistere contro i [[confirmation bias\|confirmation bias]], [[disconfirmation bias\|disconfirmation bias]] e tutti i rischi che derivano dalla [[dissonanza cognitiva\|dissonanza cognitiva]]?
      Uno dei modelli tattici che possiamo utilizzare è quello del [[pensare in grigio\|pensare in grigio]]. Si tratta di un modello che ci invita a pensare non in termini estremistici di bianco e nero, ma di accettare l’ipotesi (anzi ricercare) che sia grigia.
      Per mettere in pratica questo modello, quindi ricercare il grigio, è necessario semplicemente pazientare, attendere di avere tutte le informazioni rilevanti a disposizioni e solo poi prendere una decisione che sia il più razionale possibile.
- Devil’s advocate position. This was once an official position in the Catholic Church used during the process of canonizing people as saints. Once someone is canonized, the decision is eternal, so it was critical to get it right. Hence this position was created for someone to advocate from the Devil’s point of view against the deceased person’s case for sainthood.
    - Tags: [[blu\|blu]] 
- playing the Devil’s advocate means taking up an opposing side of an argument, even if it is one you don’t agree with. One approach is to force yourself literally to write down different cases for a given decision or appoint different members in a group to do so. Another, more effective approach is to proactively include people in a decision-making process who are known to hold opposing viewpoints. Doing so will help everyone involved more easily see the strength in other perspectives and force you to craft a more compelling argument in favor of what you believe. As Charlie Munger says, “I never allow myself to have an opinion on anything that I don’t know the other side’s argument better than they do.”
    - Note: Quale altro [[mental model\|mental model]] ci permette di resistere al [[confirmation bias\|confirmation bias]], [[disconfirmation bias\|disconfirmation bias]] ed i rischi che derivano dalla [[dissonanza cognitiva\|dissonanza cognitiva]] ?
      Il modello dell’ [[avvocato del diavolo\|avvocato del diavolo]], si tratta di un modello in cui ci arroghiamo il compito di tentare di essere gli avvocati di una ipotesi (anche se magari non la supportiamo, anzi, soprattutto se non la supportiamo).
      Possiamo farlo includendo nel processo decisionale persone che abbiano visioni opposte sulla questione, oppure scrivere da noi le casistiche derivanti dalle diverse ipotesi in contrapposizione.
- when you are in uncertain situations where you do not have encoded knowledge, you must use your slower thinking: driving on new roads, doing complex math, digging into your memory to recall someone you used to know. These are not mindless tasks.
    - Note: In quali casi dovremmo utilizzare i [[mental models\|mental models]] per prendere una decisione? Nei casi in cui è necessario il tipo di [[pensiero lento\|pensiero lento]], quelli in cui non abbiamo nel nostro cervello una conoscenza delle cose già presente e diventata istintiva.
      In quei casi utilizzare i [[mental models\|mental models]] ci permette di arrivare ad una soluzione razione, ma per farlo serve proprio il tempo di analizzare, fermarsi, riflettere.
- using mental models over time is a slow and steady way to become more antifragile, making you better able to deal with new situations over time. Of course, the better the information you put into your brain, the better your intuition will be.
    - Note: In che modo i [[mental models\|mental models]] si collegano col concetto di [[Readwise/Books/Antifragile\|antifragile]] ?
      Si collegano grazie al fatto che, ricorrendo ai modelli mentali nel tempo, questi diventeranno per noi sempre più istintivi. Arriveremo al punto in cui il nostro istinto attingerà dal bacino dei modelli mentali invece che dal nostro cervello privo di esperienza e più facile agli errori. Questo ci renderà di fatto più antifragili, ci permetterà di mantenere l’ istinto (di solito propenso agli errori ed estremo) ma sarà indirizzato a qualcosa di meno fallibile.
- As part of its work, the commission conducted a postmortem. In medicine, a postmortem is an examination of a dead body to determine the root cause of death. As a metaphor, postmortem refers to any examination of a prior situation to understand what happened and how it could go better next time. At DuckDuckGo, it is mandatory to conduct a postmortem after every project so that the organization can collectively learn and become stronger (antifragile). One technique commonly used in postmortems is called 5 Whys, where you keep asking the question “Why did that happen?” until you reach the root causes.
    - Note: In cosa consiste il [[report di postmortem\|report di postmortem]] ed in che modo ci permette di arrivare alle cause effettive di un evento, la [[radice di un problema\|radice di un problema]] ?
      Consiste nel cercare di capire (alla fine di qualcosa, un progetto, un lavoro, qualcosa) quale è stato il percorso decisionale e dove ci sono stati errori, lo si capisce usando varie tecniche, quale ad esempio quella del [[5 why\|5 why]] che a sua volta si collega al [[first principle thinking\|first principle thinking]].
      Arrivando alla radice di un problema riusciamo a capire quale è stata la causa originaria e vera di qualcosa, così da poterla risolvere ed evitare nelle future sue ricorrenze.
- Sometimes you may want something to be true so badly that you fool yourself into thinking it is likely to be true. This feeling is known as optimistic probability bias, because you are too optimistic about the probability of success. NASA managers were way too optimistic about the probability of success, whereas the engineers who were closer to the analysis were much more on target. Root cause analysis, whether you use 5 Whys or some other framework, helps you cut through optimistic probability bias, forcing you to slow down your thinking, push through your intuition, and deliberately uncover the truth.
    - Note: Quale altro bias ci può portare a prendere decisioni sbagliate affrettandole e rendendole sempre più istintive?
      Si tratta de [[bias dell’ottimismo\|bias dell’ottimismo]], un bias che ci porta a considerare le probabilità del verificarsi di un evento immotivatamente più alte se l’ evento in questione ci genera entusiasmo. Riusciamo ad evitare questo bias proprio andando alla ricerca della [[radice di un problema\|radice di un problema]] indagandola tramite [[5 why\|5 why]] oppure altre tecniche.
- To avoid mental traps, you must think more objectively. Try arguing from first principles, getting to root causes, and seeking out the third story. Realize that your intuitive interpretations of the world can often be wrong due to availability bias, fundamental attribution error, optimistic probability bias, and other related mental models that explain common errors in thinking. Use Ockham’s razor and Hanlon’s razor to begin investigating the simplest objective explanations. Then test your theories by de-risking your assumptions, avoiding premature optimization. Attempt to think gray in an effort to consistently avoid confirmation bias. Actively seek out other perspectives by including the Devil’s advocate position and bypassing the filter bubble. Consider the adage “You are what you eat.” You need to take in a variety of foods to be a healthy person. Likewise, taking in a variety of perspectives will help you become a super thinker.
    - Note: Come possiamo sbagliare meno volte? Punti principali
- ALL YOUR ACTIONS HAVE CONSEQUENCES, but sometimes those consequences are unexpected. On the surface, these unintended consequences seem unpredictable. However, if you dig deeper, you will find that unintended consequences often follow predictable patterns and can therefore be avoided in many situations. You just need to know which patterns to look out for—the right mental models.
    - Note: In che modo i [[mental models\|mental models]] possono aiutarci con le conseguenze imprevedibili delle nostre azioni?
- Any shared resource, or commons, is vulnerable to this tragedy. Overfishing, deforestation, and dumping waste have obvious parallels to overgrazing, though this model extends far beyond environmental issues. Each additional spam message benefits the spammer who sends it while simultaneously degrading the entire email system. Collective overuse of antibiotics in medicine and agriculture is leading to dangerous antibiotic resistance. People make self-serving edits to Wikipedia articles, diminishing the overall reliability of the encyclopedia. In each of these cases, an individual makes what appears to be a rational decision (e.g., prescribing an antibiotic to a patient who might have a bacterial infection). They use the common resource for their own benefit at little or no cost (e.g., each course of treatment has only a small chance of increasing resistance). But as more and more people make the same decision, the common resource is collectively depleted, reducing the ability for everyone to benefit from it in the future (e.g., the antibiotic becomes much less useful).
    - Note: In cosa consiste la [[tragedia dei commons\|tragedia dei commons]] ed in che modo può essere utilizzata come un [[mental models\|mental models]] ?
      La tragedia consiste nel fatto che ogni risorsa, che sia comune, si troverà danneggiata e col tempo irrimediabilmente distrutta se quelli che la sfruttano possono utilizzare questa risorsa comune in maniera gratuita e per il proprio bene. La somma dei risultati del bene individuale porterà al deterioramento del bene comune.
      Ne è un ottimo esempio Wikipedia, una risorsa comune a tutti gli utenti di internet, ognuno può aggiungere un contributo e chiunque vuole farlo lo fa in libertà, questo però porta col tempo Wikipedia a perdere di credibilità ed a perdere la sua utilità.
- the tragedy of the commons arises from what is called the tyranny of small decisions, where a series of small, individually rational decisions ultimately leads to a system-wide negative consequence, or tyranny.
    - Note: La [[tragedia dei commons\|tragedia dei commons]] da quale dinamica è causata?
      Dalla [[tirannia delle piccole decisioni\|tirannia delle piccole decisioni]], si tratta di ciò che accade quando all’ interno di un gruppo si ha la consapevolezza che le conseguenze delle azioni non saranno specificatamente rivolte a sé stessi ma a tutto il gruppo, in questi casi le decisioni dei singoli (anche se piccole e razionali) porteranno comunque a conseguenze più grandi (e forse dannose).
- The tyranny of small decisions can be avoided when someone who has a view over the whole system can veto or curb particular individual decisions when broad negative impacts can be foreseen. When the decisions are all your own, you could do this for yourself. For example, to stop your out-of-control spending, you could self-impose a budget, checking each potential purchase against the budget to see if it’s compatible with your spending plan. You could do the same for your time management, by more strictly regulating your calendar. When decisions are made by more than just you, then a third party is usually needed to fill this role,
    - Note: In che modo si può evitare la [[tirannia dei piccoli problemi\|tirannia dei piccoli problemi]] e quindi [[la tragedia dei commons\|la tragedia dei commons]] ?
      Si può evitare introducendo un elemento che controlli le piccole decisioni prese dagli individui all’interno del sistema, implementando un regolamento ecc
      Quando le decisioni siamo solo noi e riguardano solo noi, allora quell’ elemento siamo noi stessi, quando però le decisioni sono prese da gruppi di individui e riguardano tutti allora quell’ elemento deve essere un elemento esterno allo stesso sistema.
- Another cause of issues like the tragedy of the commons is the free rider problem, where some people get a free ride by using a resource without paying for it.
    - Note: Quale può essere un’altra causa della [[tragedia dei commons\|tragedia dei commons]]? Il [[problema dei free rider\|problema dei free rider]].
      Con questo problema si indica chiunque utilizzi liberamente un bene pubblico (generalmente) che prevede un pagamento per il suo utilizzo.
- Vaccinations provide an illustrative example that combines all these models (tragedy of the commons, free rider problem, tyranny of small decisions, public goods), plus one more: herd immunity. Diseases can spread only when they have an eligible host to infect. However, when the vast majority of people are vaccinated against a disease, there are very few eligible new hosts, since most people (in the herd) are immune from infection due to getting vaccinated. As a result, the overall public is less susceptible to outbreaks of the disease. In this example, the public good is a disease-free environment due to herd immunity, and the free riders are those who take advantage of this public good by not getting vaccinated. The tyranny of small decisions can arise when enough individuals choose not to get vaccinated, resulting in an outbreak of the disease, creating a tragedy of the commons.
    - Note: Quale può essere un esempio di cosa che mette in mostra tutte le cose che riguardano e portano alla [[tragedia dei commons\|tragedia dei commons]] ?
- All these unintended consequences we’ve been talking about have a name from economics: externalities, which are consequences, good or bad, that affect an entity without its consent, imposed from an external source. The infant who cannot be vaccinated, for example, receives a positive externality from those who choose to vaccinate (less chance of getting the disease) and a negative externality from those who do not (more chance of getting the disease).
    - Note: Come possiamo chiamare le conseguenze non volute delle nostre azioni e che hanno impatto sul comune? [[Esternalità\|Esternalità]] e sono da intendersi come appunto le azioni le cui conseguenze possono avere impatto sul bene comune.
      Tali esternalità possono essere positive o negative, a seconda dell’impatto che hanno sulla vita dell’insieme e degli individui che ne fanno parte.
- Externalities occur wherever there are spillover effects, which happen when an effect of an activity spills over outside the core interactions of the activity.
    - Note: In che modo si generano le [[esternalità\|esternalità]] ? Attraverso lo [[spill over effect\|spill over effect]] che accade quando le conseguenze di un’attività ricadono fuori dal centro focale dell’ attività stessa.
- Addressing negative externalities is often referred to as internalizing them. Internalizing is an attempt to require the entity that causes the negative externality to pay for it. Ideally the “price” attached to the unwanted activity is high enough that it totally covers the cost of dealing with that activity’s consequences. A high price can also stop the harm from occurring in the first place. If you see a sign warning of a five-hundred-dollar fine for littering, you will be sure to find a trash can. There are many ways to internalize negative externalities, including taxes, fines, regulation, and lawsuits.
    - Note: Cosa accade quando si cerca di risolvere le [[esternalità\|esternalità]] di un problema? In tal caso si sta cercando di [[internalizing\|internalizing]] il problema.
      Per internalizzare il problema ci sono tanti modi, a seconda del problema: multe, tasse ecc. Di base si cerca di fare in modo che chi ha creato il problema paghi il costo che deriva dalla totale gestione del problema a livello collettivo.
      In questo modo si possono stimare le multe per buttare la spazzatura nella zona sbagliata ecc.
- Another way to internalize externalities is through a marketplace. Ronald Coase won the Nobel Prize in economics in 1991 in part for what has become known as the Coase theorem, essentially a description of how a natural marketplace can internalize a negative externality. Coase showed that an externality can be internalized efficiently without further need for intervention (that is, without a government or other authority regulating the externality) if the following conditions are met: Well-defined property rights Rational actors Low transaction costs When these conditions are met, entities surrounding the externality will transact among themselves until the extra costs are internalized.
- the Boston Common example, the externality from overgrazing was internalized by setting a limit on the number of cows per farmer (regulation). There were no property rights though.
    - Note: Cosa afferma il [[teorema di Coese\|teorema di Coese]] ? Afferma che i mercati naturali possano internalizzare le esternalità in maniera naturale se rispettano tre condizioni:
      - Abbiano dei diritti di proprietà,
      - Abbiano dei bassi costi definiti di transazione;
      - Siano popolati da agenti razionali;
- The Coase theorem holds that instead of limiting the cows, another solution would have been to simply divide the grazing rights to the commons property among the farmers. The farmers could then trade the grazing rights among themselves, creating an efficient marketplace for the use of the commons.
    - Note: Secondo la [[tesi di Coese\|tesi di Coese]] in che modo si sarebbe potuto risolvere il problema dei Commons di Boston invece che limitando il numero di mucche che li popolavano?
      Si sarebbe dovuto implementare una zona di mercato libero nei Commons, tale zona avrebbe dovuto suddividere i Commons in zone a proprietà dei contadini ed ognuno di questi avrebbe dovuto pagare una commissione per avere dello spazio da utilizzare. In questo modo il sistema si sarebbe autoregolamentato, così come i contadini.
- cap-and-trade systems, which are modern-day applications of the Coase theorem. The way these systems work is that the government requires emitters to hold permits for the amount of pollutants they emit. The government also sets a fixed number of total permits, which serves as the emission cap in the market, similar to the imposed limit on the number of cows that could graze on Boston Common. Then companies can trade permits on an open exchange. Such a system satisfies the conditions of the Coase theorem because property rights are well defined through the permitting process, companies act rationally to maximize their profits, and the open market provides low transaction costs.
    - Note: In che modo i governi applicano il [[teorema di Coese\|teorema di Coese]] all’ inquinamento ed alle aziende che producono inquinamento? Grazie al sistema [[cap and trade\|cap and trade]] che prevede proprio l’ applicazione del suddetto teorema e delle condizioni che lo regolamentano.
      All’atto pratico:
      - le aziende devono avere dei permessi per poter bruciare combustibili fossili;
      - il governo impone un limite legale di emissioni derivanti da combustibili fossili, se ne vuoi di più devi pagare;
      - le aziende sono individui razionali in quanto cercheranno sempre di massimizzare il loro profitto;
      - i permessi per le emissioni sono acquistabili tra le varie aziende in maniera aperta;
- Another set of unintended consequences can arise when people assess risk differently based on their individual positions and perspectives. These types of complications happen a lot with insurance, where risk assessments create financial consequences. For example, will you drive more recklessly in a rental car after you purchase extra rental insurance, simply because you’re more protected financially from a crash? On average, people do.
- moral hazard, is where you take on more risk, or hazard, once you have information that encourages you to believe you are more protected.
    - Note: In cosa consiste il [[moral hazard\|moral hazard]] ? Consiste nel fatto che quando si ha la percezione di essere protetti, allora si tende ad agire in maniera più sconsiderata.
- Moral hazards can also occur when a person or company serves as an agent for another person or company, making decisions on behalf of this entity, known as the principal. The problem arises when the agent takes on more risk than the principal would if the principal were acting alone, since the agent is more protected when things go wrong. For instance, when financial advisers manage your money,
    - Note: In quali altre casistiche si può verificare il fenomeno del [[moral hazard\|moral hazard]] ? Quelle di consulenza finanziaria, o qualsiasi altra consulenza. Insomma tutte quelle casistiche in cui è previsto che qualcuno prenda decisioni al posto di qualcun altro, senza patirne le conseguenze dirette.
- Agency can lead to other issues as well, collectively known as the principal-agent problem, where the self-interest of the agent may lead to suboptimal results for the principal across a wide variety of circumstances.
    - Note: A quale altro problema si collega quello del [[moral hazard\|moral hazard]] ? A quello del [[problema principale-agente\|problema principale-agente]] in cui l’agente non segue necessariamente gli interessi di chi gli commissiona il lavoro.
      Questo accade spesso con i politici o gli agenti che vendono case.
- Moral hazard and principal-agent problems can occur because of asymmetric information, where one side of a transaction has different information than the other side; that is, the available information is not symmetrically distributed. Real estate agents have more information about the real estate market than sellers, so it is hard to question their recommendations.
    - Note: Quale è la causa principale dei [[problema del principale-agente\|problema del principale-agente]] ? 
      La causa è la distribuzione delle informazioni ed il fatto che sia [[informazione asimmetrica\|informazione asimmetrica]] in quanto l’ agente talvolta ha più informazioni del principale riguardo il mercato e le sue opportunità.
- Disclosure laws and the increase in open information via the internet can reduce the effects of asymmetric information.
    - Note: Quali sono le cose che possono ridurre il rischio e gli effetti di [[informazione asimmetrica\|informazione asimmetrica]] ? La diffusione di internet e le leggi di divulgazione.
- When parties select transactions that they think will benefit them, based at least partially on their own private information, that’s called adverse selection. People who know they are going to need dental work are more likely to seek out dental insurance. This unfortunately drives up the price for everyone. Two ways to mitigate adverse selection in the insurance market are to mandate participation, as many localities do for car insurance, and to distinguish subpopulations based on their risk profiles, as life insurers do for smokers.
    - Note: Cosa si verifica quando nei casi di [[informazione asimmetrica\|informazione asimmetrica]] la parte ha più informazioni è quella del principale, del consumatore? 
      Si hanno casistiche di [[selezione avversa\|selezione avversa]] in cui è il diretto interessato dall’ assicurazione ad avere più informazioni riguardo il suo profilo di rischio. Si cerca di mitigare questa situazione tramite il demandare la partecipazione e tramite la segmentazione dei profili di rischio.
- rampant and persistent asymmetric information in a market can lead to its collapse.
    - Note: Quale è il rischio di una [[informazione asimmetrica\|informazione asimmetrica]] senza regolamenti ed in costante crescita? 
      Sono nel fatto che questa può portare al collasso di un mercato.
- The mental models from the last section (tragedy of the commons, externalities, etc.) and those from this section (moral hazard, information asymmetry, etc.) are signs of market failure, where open markets without intervention can create suboptimal results, or fail. To correct a market failure, an outside party must intervene in some way. Unfortunately, these interventions themselves can also fail, a result called government failure or political failure.
- Antibiotics present a good case study in market and political failure.
    - Note: Quale può essere un buon case study riguardo i [[fallimenti politici\|fallimenti politici]] e [[fallimenti governativi\|fallimenti governativi]]?
- Goodhart’s law summarizes the issue: When a measure becomes a target, it ceases to be a good measure. This more common phrasing is from Cambridge anthropologist Marilyn Strathern in her 1997 paper “‘Improving Ratings’: Audit in the British University System.” However, the “law” is named after English economist Charles Goodhart, whose original formulation in a conference paper presented at the Reserve Bank of Australia in 1975 stated: “Any observed statistical regularity will tend to collapse once pressure is placed upon it for control purposes.”
    - Note: In cosa consiste la [[legge di Goodhart\|legge di Goodhart]] ?
      Questa legge afferma che ogni stima statistica smetterà di avere una sua applicazione nel momento in cui la si pone come obiettivo, o semplicemente si pone attenzione su di essa a fini di controllo.
- Both describe the same basic phenomenon: When you try to incentivize behavior by setting a measurable target, people focus primarily on achieving that measure, often in ways you didn’t intend. Most importantly, their focus on the measure may not correlate to the behavior you hoped to promote. High-stakes testing culture—be it for school examinations, job interviews, or professional licensing—creates perverse incentives to “teach to the test,” or worse, cheat.
    - Note: Cos’è un [[incentivo perverso\|incentivo perverso]] ? 
      Si tratta di quelle casistiche in cui, per migliorare un comportamento, si cerca di intervenire su una metrica specifica e totalmente concentrandosi su di essa.
      Una situazione del genere sposta il focus dal comportamento che si cerca di migliorare all’ obiettivo di raggiungere la metrica e basa. E per raggiugnere questa metrica ci sono tante soluzioni che non prevedono il miglioramento del comportamento che si voleva perseguire.
- Similarly, hospitals and colleges have been increasingly criticized for trying to achieve rankings at the expense of providing quality care and education, the very things the rankings are supposed to be measuring.
    - Note: Quale può essere un [[incentivo perverso\|incentivo perverso]] ?
- It’s like a wish-granting genie who finds loopholes in your wishes, meeting the letter of the wish but not its spirit, and rendering you worse off than when you started. In fact, there is a mental model for this more specific situation, called the cobra effect, describing when an attempted solution actually makes the problem worse.
    - Note: A quale situazione può essere paragonata una situazione di [[incentivo perverso\|incentivo perverso]] ? 
      A quella di un genio della lampada che segue alla lettera i tuoi desideri senza afferrarne il vero significato, quindi ti peggiora la situazione invece che migliorarla. Questo rimanda al [[mental models\|mental models]] di [[effetto cobra\|effetto cobra]]
- When the British were governing India, they were concerned about the number of these deadly snakes, and so they started offering a monetary reward for every snake brought to them. Initially the policy worked well, and the cobra population decreased. But soon, local entrepreneurs started breeding cobras just to collect the bounties. After the government found out and ended the policy, all the cobras that were being used for breeding were released, increasing the cobra population even further.
    - Note: Da quale vicenda storica deriva il suo nome l’ [[effetto cobra\|effetto cobra]] ?
- The Streisand effect applies to an even more specific situation: when you unintentionally draw more attention to something when you try to hide it. It’s named for entertainer Barbra Streisand, who sued a photographer and website in 2003 for displaying an aerial photo of her mansion, which she wanted to remain private. Before the suit, the image had been downloaded a total of six times from the site; after people saw news stories about the lawsuit, the site was visited hundreds of thousands of times, and now the photo is free to license and is on display on Wikipedia and many other places.
    - Note: Cosa è l’ [[effetto Streisand\|effetto Streisand]] ed a quale vicenda si collega?
      Si collega a quando Barbara Streisand cercò di nascondere la foto di casa sua, che era uscita online, e nel farlo non fece altro che attirare ancora più attenzione sulla cosa e rese la foto in questione ancora più vista.
      Questo effetto, infatti, indica quei casi in cui, nel cercare di nascondere qualcosa, non facciamo altro che attirare attenzione proprio sulla cosa che cerchiamo di nascondere.
- A related model to watch out for is the hydra effect, named after the Lernaean Hydra, a beast from Greek mythology that grows two heads for each one that is cut off. When you arrest one drug dealer, they are quickly replaced by another who steps in to meet the demand. When you shut down an internet site where people share illegal movies or music, more pop up in its place.
    - Note: In cosa consiste l’ [[effetto Idra\|effetto Idra]] ? 
      Consiste nei casi in cui, eliminando un problema, a sostituirlo emerge (o emergono subito) altri problemi di simile natura: come le teste dell’idra o come gli spacciatori.
- another trap to watch out for is the observer effect, where there is an effect on something depending on how you observe it, or even who observes it.
    - Note: In cosa consiste l’ [[observer effect\|observer effect]] ? 
      Consiste nel fatto che nel momento in cui si osserva un fenomeno, si cambia lo stesso comportamento del fenomeno, tale cambiamento dipende sia dal come si osserva il fenomeno sia addirittura da chi osserva il fenomeno stesso.
- In the legal context where the term chilling effect originated, it refers to when people feel discouraged, or chilled, from freely exercising their rights, for fear of lawsuits or prosecution. More generally, chilling effects are a type of observer effect where the threat of retaliation creates a change in behavior.
    - Note: Quale altro effetto sul nostro comportamento deriva da [[observer effect\|observer effect]] ? Il [[chilling effect\|chilling effect]] che consiste nella modifica di un comportamento che deriva dalla paura della punizione.
- Like Goodhart’s law and related models, observer and chilling effects concern unintended consequences that can happen after you take a deliberate action—be it a policy, experiment, or campaign. Again, it is best to think ahead about what behaviors you are actually incentivizing by your action, how there might be perverse incentives at play, and what collateral damage or even blowback these perverse incentives might cause.
    - Note: Cosa è consigliato fare riguardo la [[legge di Goodhart\|legge di Goodhart]] ed i modelli che ne derivano ? 
      Visto che questi modelli mostrano quello che può accadere nel momento in cui si decide di intervenire in un dato contesto per modificare determinati comportamenti, allora è necessario ben valutare quali comportamenti si vuole modificare e se il gioco vale la candela.
- There is a broader class of unintended consequences to similarly watch out for, which also involve making seemingly good short-term decisions that can still add up to a bad outcome in the long term. The mental model often used to describe this class of unintended consequences is called the boiling frog: Suppose a frog jumps into a pot of cold water. Slowly the heat is turned up and up and up, eventually boiling the frog to death. It turns out real frogs generally jump out of the hot water in this situation, but the metaphorical boiling frog persists as a useful mental model describing how a gradual change can be hard to react to, or even perceive.
    - Note: Quale [[mental models\|mental models]] si riferisce al fenomeno per cui piccole azioni e scelte, specialmente se graduali, possono portare in maniera inconsapevole a pessime conseguenze ? Quello della [[boiling frog\|boiling frog]].
- short-termism describes these types of situations, when you focus on short-term results, such as quarterly earnings, over long-term results, such as five-year profits. If you focus on just short-term financial results, you won’t invest enough in the future. Eventually you will be left behind by competitors who are making those long-term investments, or you could be swiftly disrupted by new upstarts
    - Note: Da che modo di pensare discende la situazione della [[boling frog\|boling frog]] ?
      Dal modo di pensare basato sul breve termine, questo modo di pensiero viene definito [[short-termism\|short-termism]].
- The software industry has a name for the consequences of short-termism: technical debt. The idea comes from writing code: if you prioritize short-term code fixes, or “hacks,” over long-term, well-designed code and processes, then you accumulate debt that will eventually have to be paid down by future code rewrites and refactors. Accumulating technical debt isn’t necessarily harmful—it can help projects move along faster in the short term—but it should be done as a conscientious observer, not as an unaware boiling frog.
    - Note: In che modo si può declinare lo [[short-termism\|short-termism]] nel campo della programmazione? Tale modello si identifica con il concetto di [[debito tecnico\|debito tecnico]] con cui ci si riferisce a quando, per pensare solo a breve termine, si preferiscono soluzioni immediate e rapide rispetto a qualcosa di più strutturato. 
      Così facendo il codice che si scrive diventa poco funzionale e strutturato sulla lunga durata e prima o poi si romperà. Utilizzare soluzioni rapide e veloci non è in sé da rifiutare ma bisogna osservarlo ed accumulare [[debito tecnico\|debito tecnico]] in maniera consapevole, per evitare di doversi ritrovare poi con la necessità di ricostruire tutto perché qualcosa si è rotto.
- The general model for this impact comes from economics and is called path dependence, meaning that the set of decisions, or paths, available to you now is dependent on your past decisions. Sometimes an initial decision or event may seem innocuous at first, but it turns out to strongly influence or limit your possible outcomes in the long run.
    - Note: Da quale più generale [[mental models\|mental models]] discende il concetto di [[debito tecnico\|debito tecnico]]?
      Nasce da quello denominato [[dipendenza dal sentiero\|dipendenza dal sentiero]] con cui si afferma come ogni scelta che facciamo, anche la più piccola e buona, ci indirizza verso un sentiero dal quale sarà poi sempre pi difficile allontanarsi, scelta dopo scelta.
- For any decision, ask yourself: What kind of debt am I incurring by doing this? What future paths am I taking away by my actions today?
- Another model from economics offers some reprieve from the limitations of path dependence: preserving optionality. The idea is to make choices that preserve future options. Maybe as a business you put some excess profits into a rainy-day fund, or as an employee you dedicate some time to learning new skills that might give you options for future employment.
    - Note: Come si chiama quel [[mental models\|mental models]] con cui ogni scelta che si prende si cerca di prenderla in maniera tale da mantenere aperti sempre più sentieri ed evitare così la trappola della [[dipendenza dal sentiero\|dipendenza dal sentiero]]? 
      Si tratta del modello del [[preservare l’opzionalità\|preservare l’opzionalità]] con cui si cerca appunto di prendere ogni scelta in maniera tale da avere sempre più opzioni aperte.
- The downside of keeping many options open is that it often requires more resources, increasing costs. Think of going to school while you also have a full-time job, maintaining multiple homes, or exploring several lines of business in one parent company. You need to find the right balance between preserving optionality and path dependence.
- One model that can help you figure out how to strike this balance in certain situations is the precautionary principle: when an action could possibly create harm of an unknown magnitude, you should proceed with extreme caution before enacting the policy. It’s like the medical principle of “First, do no harm.”
    - Note: Da quale [[mental models\|mental models]] più generale nasce il concetto di [[debito tecnico\|debito tecnico]] ? Tutto nasce dal modello della [[dipendenza dal sentiero\|dipendenza dal sentiero]] che afferma come le scelte che prendiamo, in ogni caso, anche se piccole ci indirizzano sempre più lungo un sentiero dal quale sarà sempre più difficile allontanarsi, scelta dopo scelta.
- 
    - Note: In che modo si può risolvere il più grande contro del [[mental models\|mental models]] del [[preservare l’opzionalità\|preservare l’opzionalità]] ?
      Lo si risolve cercando un equilibrio tra il [[preservare l’opzionalità\|preservare l’opzionalità]] e la [[dipendenza dal sentiero\|dipendenza dal sentiero]] ed il modello che permette di trovare questo equilibrio è quello del [[principio precauzionale\|principio precauzionale]] che afferma come, ad ogni scelta, la strada più sensata sia quella di essere estremamente cauti alla scelta di cui ignoriamo la portata dei danni.
- These mental models are the most useful when thinking about existential risks. After all, in the tale of the boiling frog, the frog dies. Therefore, you want first to assess what substantial harms could arise in the long term, then work backward to assess how your short-term decisions (or lack thereof) might be contributing to long-term negative scenarios (a process that we cover in more depth in Chapter 6). With this knowledge, you can then take the necessary level of precaution, paying down technical debt as needed, happily preventing yourself from becoming the boiling frog.
    - Note: In che modo è consigliato applicare i [[mental models\|mental models]] chiamati [[preservare l’opzionalità\|preservare l’opzionalità]], [[dipendenza dal sentiero\|dipendenza dal sentiero]] e [[principio di precauzione\|principio di precauzione]] ???
      Si consiglia di applicarli andando a trovare i danni peggiori che una scelta, di cui ignoriamo le potenzialità negative, potrebbe causare e procedere poi a ritroso andando a capire le scelte a breve termine che potremmo fare (e che dovremmo quindi evitare) per non ricevere il danno. 
      In pratica valutiamo una decisione di cui ignoriamo i potenziali danni sul lungo termine, ipotizziamo il danno peggiore che questa ci potrebbe generare (e che temiamo ne consegua), individuato il potenziale danno procediamo a ritroso e consideriamo tutte le piccole decisioni che potrebbero portarci a quel danno e ne diventiamo coscienti così da evitare di prenderle in maniera sbagliata.
- you need some information to make good decisions, but too much information leads to information overload, which complicates a decision-making process. The excess information can overload the processing capacity of the system,
    - Note: Come si definisce lo stato in cui ci troviamo quando acquisiamo troppe informazioni, così tante che bloccano o rallentano il sistema decisionale? Si chiama [[information overload\|information overload]]
- analysis paralysis, where your decision making suffers from paralysis because you are over-analyzing the large amount of information available.
    - Note: Come si chiama la situazione in cui ci troviamo in seguito ad [[information overload\|information overload]] ed in che stato ci induce?
      Si chiama [[paralisi dell’analisi\|paralisi dell’analisi]] e blocca interamente il sistema decisionale impedendoci di prendere una decisione in funzione delle informazioni che abbiamo, e che sono troppe a causa della loro enorme disponibilità.
- The model perfect is the enemy of good drives home this point—if you wait for the perfect decision, or perfect anything, really, you may be waiting a long time indeed. And by not making a choice, you are actually making a choice: you are choosing the status quo, which could be considerably worse than one of the other choices you could already have made.
    - Note: In quale [[mental models\|mental models]] ci porta la [[paralisi dell’ analisi\|paralisi dell’ analisi]] e l’ [[information overload\|information overload]] ? Ci porta nel modello del [[perfezione nemica della qualità\|perfezione nemica della qualità]] con cui intendiamo che attendere il momento perfetto, la situazione perfetta, l’occasione perfetta anche se magari ci può sembrare utile, in alcuni casi potrebbe essere solo frutto di [[information overload\|information overload]] e [[paralisi dell’ analisi\|paralisi dell’ analisi]] e quindi in realtà non stiamo aspettando in maniera strategica ma lo stiamo facendo perché incapacitati a prendere una decisione.
      Questo significa che se anche dovesse effettivamente manifestarsi la situazione perfetta da cogliere, comunque non lo faremmo perché paralizzati.
      C’è inoltre da considerare che anche l’ atto stesso di non scegliere, è in realtà una scelta, la scelta di mantenere inalterato lo status quo.
- There is a natural conflict between the desire to make decisions quickly and the feeling that you need to accumulate more information to be sure you are making the right choice. You can deal with this conflict by categorizing decisions as either reversible decisions or irreversible decisions. Irreversible decisions are hard if not impossible to unwind. And they tend to be really important. Think of selling your business or having a kid.
    - Note: In che modo allora si può cercare un equilibrio tra la giusta volontà di prendere delle decisioni in maniera informata e la necessità di prendere delle decisioni senza incappare nella [[paralisi dell’analisi\|paralisi dell’analisi]] e del [[perfezione nemica di qualità\|perfezione nemica di qualità]] ?
      Si applica un modello basato sul distinguere le decisioni in [[decisioni irreversibili\|decisioni irreversibili]] e [[decisioni reversibili\|decisioni reversibili]].
      Le prime sono quelle decisioni che hanno un impatto sulla nostra vita e che, se vogliamo, non possiamo annullare, come ad esempio vendere il proprio business oppure avere un figlio.
      Le seconde invece sono reversibili.
      Per prendere queste due diverse tipologie di decisioni sono necessari due diversi processi decisionali.
- Some decisions are consequential and irreversible or nearly irreversible—one-way doors—and these decisions must be made methodically, carefully, slowly, with great deliberation and consultation. If you walk through and don’t like what you see on the other side, you can’t get back to where you were before. . . . But most decisions aren’t like that—they are changeable, reversible—they’re two-way doors. If you’ve made a suboptimal [reversible] decision, you don’t have to live with the consequences for that long. You can reopen the door and go back through. . . . As organizations get larger, there seems to be a tendency to use the heavy-weight [irreversible] decision-making process on most decisions, including many [reversible] decisions. The end result of this is slowness, unthoughtful risk aversion, failure to experiment sufficiently, and consequently diminished invention.
    - Note: Come differiscono i processi decisionali necessari per prendere [[decisioni reversibili\|decisioni reversibili]] e [[decisioni irreversibili\|decisioni irreversibili]] ? Differiscono essenzialmente nella lentezza e metodicità del processo decisionale.
- They found that a greater number of choices increased the decision time logarithmically, in a formulation now known as Hick’s law. Hick’s law is regularly cited as an important factor in user-experience designs, such as in the design of restaurant menus, website navigation, and forms (offline or online).
    - Note: Quale formula (o legge) può aiutarci a combattere il fenomeno della [[paralisi da analisi\|paralisi da analisi]] ?
      La legge nota come [[Hick’s law\|Hick’s law]] che afferma come all’aumentare delle opzioni offerte per una scelta, il tempo per prendere questa decisioni aumenterà in maniera logaritmica.
      Per questo un altro modo per combattere la paralisi è proprio quello di ridurre il più possibile le opzioni, oppure invece di prendere un’unica grande decisione, ridurla in più piccole decisioni con più limitate opzioni.
- One way to do this is to give yourself or others a multi-step decision with fewer choices at each step, such as asking what type of restaurant to go to (Italian, Mexican, etc.), and then offering another set of choices within the chosen category.
- There is also a model that explains the downside of making many decisions in a limited period: decision fatigue. As you make more and more decisions, you get fatigued, leading to a worsening of decision quality. After taking a mental break, you effectively reset and start making higher-quality decisions again.
    - Note: Cosa accade quando invece di avere troppe opzioni per fare una scelta, ci ritroviamo nella situazione in cui prendiamo troppe decisioni in un determinato limite di tempo? 
      Ci ritroviamo nella situazione della [[decision fatigue\|decision fatigue]] con cui ogni decisione che prendiamo peggiora la qualità delle decisioni stesse, come se il nostro muscolo per prendere decisioni fosse stanco e non riuscisse più a farcela.
      Quando ci ritroviamo in questa situazione, prendendo uno stacco e resettando il sistema, ritorniamo a prendere decisioni in maniera efficace.
- Murphy’s law: Anything that can go wrong, will go wrong. It’s named after aerospace engineer Edward Murphy, from his remarks after his measurement devices failed to perform as expected. It was intended as a defensive suggestion, to remind you to be prepared and to have a plan for when things go wrong.
- In any situation where you can spot spillover effects (like a polluting factory), look for an externality (like bad health effects) lurking nearby. Fixing it will require intervention either by fiat (like government regulation) or by setting up a marketplace system according to the Coase theorem (like cap and trade). Public goods (like education) are particularly susceptible to the tragedy of the commons (like poor schools) via the free rider problem (like not paying taxes). Beware of situations with asymmetric information, as they can lead to principal-agent problems. Be careful when basing rewards on measurable incentives, because you are likely to cause unintended and undesirable behavior (Goodhart’s law). Short-termism can easily lead to the accumulation of technical debt and create disadvantageous path dependence; to counteract it, think about preserving optionality and keep in mind the precautionary principle. Internalize the distinction between irreversible and reversible decisions, and don’t let yourself succumb to analysis paralysis for the latter. Heed Murphy’s law!
- In the business world, there is a mental model that draws on Polaris for inspiration, called north star, which refers to the guiding vision of a company. For example, DuckDuckGo’s north star is “to raise the standard of trust online.” If you know your north star, you can point your actions toward your desired long-term future. Without a north star, you can be easily “lost at sea,” susceptible to the unintended consequences of short-termism (see Chapter 2).
- For an individual, it is important to have a personal north star, or mission statement. Do you have one? If not, you should think about drafting one for yourself. If you can orient yourself toward your north star and prioritize the right activities, you can accomplish amazing things over time. There are infinite possibilities, though here are a few examples to get you thinking: Being the best parent I can be Helping refugees as best I can Saving enough to retire by age forty Maximizing my positive impact on homelessness Living simply and being happy Advancing the science of human longevity It’s okay if your north star evolves as you progress toward it.
    - Note: È consigliato avere una [[north-star\|north-star]] anche agli individui? SI, è consigliato perché grazie ad una vision personale, anzi mission, si potrà essere più concentrati sul raggiungere uno specifico obiettivo e sugli sforzi da fare per raggiungerlo.
      Tale obiettivo potrà essere aggiornato, potrà anche cambiare quando lo raggiungiamo.
- A north star is a long-term vision, so it is also okay if you don’t reach it anytime soon. However, if you don’t know where you want to go, how do you expect to ever get there?
- This is called compound interest, referring to the fact that your interest payments are growing over time, or compounding. Previous interest earned is added to the total amount each cycle, making a bigger base from which the next interest cycle is calculated.
    - Note: In cosa consiste il concetto o [[mental models\|mental models]] chiamato [[compounding interest\|compounding interest]] ? Si riferisce al concetto per cui un piccolo passo verso il nostro obiettivo, giorno dopo giorno, si va a sommare ai piccoli passi fatti gli altri giorni ed in questo modo, sulla lunga durata, ci ritroviamo con l’ aver fatto grandi passi senza nemmeno rendercene conto.
- You should be wary of fighting a two-front war, yet you probably do so every single day in the form of multitasking. When discussing intuition in Chapter 1, we explained that there are two types of thinking: low-concentration, autopilot thinking (for saying your name, walking, simple addition, etc.) and high-concentration, deliberate thinking (for everything else). You can fully perform only one high-concentration activity at a time. Your brain just isn’t capable of simultaneously focusing on two high-concentration activities at once. If you attempt this, you will be forced to context-switch between the two activities.
    - Note: Quale tipo di [[mental models\|mental models]] è molto probabile incontrare quando si parla di [[guerra su due fronti\|guerra su due fronti]] ? Quello del [[multitasking\|multitasking]] che cerchiamo tutti di fare quando ci ritroviamo a dover gestire molteplici input ma dovendo poter utilizzare la nostra parte alta dell’ attenzione solo ad uno di questi stimoli.
- If you are constantly switching between activities, you don’t end up doing much creative thinking at all. Author Cal Newport refers to the type of thinking that leads to breakthrough solutions as deep work.
    - Note: In cosa consiste il [[deep work\|deep work]] ed in che modo permette la produzione di cose creative ed innovative?
      Si ha deep work quando ci si concentra in maniera intensa ed unica (senza multitasking o altro) su una sola cosa, solo in questo modo (e quindi senza dispersioni di energia rivolte a context switching o altro) si può essere capaci di generare pensieri creativi.
- Thiel’s solution encourages deep work by strictly limiting multitasking. Of course, if you limit yourself to one activity at a time, it is critical that this top idea in your mind is an important one. Fortunately, there is also a mental model that can help you identify truly important activities. U.S. President Dwight Eisenhower famously quipped, “What is important is seldom urgent and what is urgent is seldom important.” This quote inspired Stephen Covey in 7 Habits of Highly Effective People to create the Eisenhower Decision Matrix,
    - Note: Se il [[deep work\|deep work]] ci aiuta a concentrarci su una questione per poterla risolvere e poter generare su di essa del pensiero creativo, come facciamo a capire quale è quell’attività visto che come presupposto del deep work questa deve essere unica?
      A risolvere il dubbio c’è la [[Matrice di Eisenhower\|Matrice di Eisenhower]], una matrice 2x2 in cui si collocano i task per importanza ed urgenza. Ci si deve concentrare solo sui task che sono contemporaneamente sia importanti che urgenti.
- Sayre’s law, named after political scientist Wallace Sayre, offers that in any dispute the intensity of feeling is inversely proportional to the value of the issues at stake. A related concept is Parkinson’s law of triviality, named after naval historian Cyril Parkinson, which states that organizations tend to give disproportionate weight to trivial issues. Both of these concepts explain how group dynamics can lead the group to focus on the wrong things.
    - Note: Quali [[mental models\|mental models]] ci fanno capire quanto siamo corrotti nel dare peso alle cose, specialmente se tale peso lo diamo di gruppo?
      La [[legge di Sayre\|legge di Sayre]] indica che in ogni disputa, l’intensità del sentimento in gioco è inversamente proporzionale all’importanza del problema che si sta analizzando.
      La [[Parkinson’s law of triviality\|Parkinson’s law of triviality]] invece afferma come nelle organizzazioni sia dia un peso sproporzionato a cose dal valore triviale.
- This phenomenon has become known as bike-shedding. You must try not to let yourself get sucked into these types of debates, because they rob you of time that can be spent on important issues. In the budget meeting, the agenda could instead be structured so that time is pre-allocated proportionally to the relative importance of each item, and items can also be ordered by importance. That way much greater time will be apportioned to the reactor relative to the bike shed, and the reactor discussion will take place first. You can further set strict time limits for each agenda item (called timeboxing) to ensure that any bike-shedding that does arise doesn’t take over the entire meeting.
    - Note: Cosa si intende con il fenomeno del [[bike-shedding\|bike-shedding]] e come lo si può evitare?
      Con bike shedding si intende quel fenomeno per cui, in contesti di gruppo, si preferisca discutere e rivolgere attenzione e/o tempo a quei problemi che più sembrano essere gestibili e risolvibili, quei problemi più piacevoli insomma.
      Tutti gli altri temi vengono messi da parte, anche se più importanti.
      Questa situazione si può evitare cercando di prendere delle misure prima che il contesto di gruppo si generi: magari creando una lista degli argomenti, dandogli un ordine di priorità e dei quantitativi di tempo già impostati.
- Luckily, there is an extremely powerful mental model from economics to guide you: opportunity cost. Every choice you make has a cost: the value of the best alternative opportunity you didn’t choose. As a rule, you want to choose the option with the lowest opportunity cost.
    - Note: Quale altro [[mental models\|mental models]] può aiutarci nel dare priorità ad un task o un altro? 
      Quello del [[opportunity cost\|opportunity cost]] con cui si intende il costo che ha seguire uno specifico problema, costo che si può quantificare con il mancato introito che si avrebbe seguendo l’altra opportunità, la migliore seconda opportunità che si ha a disposizione.
      Si tratta di un costo in cui è importante considerare tutto, anche il tempo.
- in negotiations there is another application of opportunity cost called BATNA, which stands for best alternative to a negotiated agreement. If you have a job offer, your BATNA is the best alternative job offer you have in hand, including your current job. You shouldn’t accept an offer worse than your BATNA, because you can always take this better alternative offer (which could be the status quo). In less clear-cut situations, it can be more challenging to understand your BATNA, and so it helps to brainstorm and literally list out all of your alternatives. This process can help you uncover additional alternatives that aren’t immediately apparent. In any case, going into a negotiation knowing your BATNA is critical to making a decision that you won’t regret.
    - Note: Quale altro metodo possiamo utilizzare per valutare la migliore opportunità su cui concentrarsi?
      Quello del [[BATNA\|BATNA]] con cui si intende, nel contesto degli accordi e negoziazioni, la miglior alternativa ad un accordo preso. Si tratta di un modello che si applica semplicemente imponendosi che non si accetterà mai un’offerta inferiore a quella che già è stata chiusa.
      Quando il contesto però è confusionario e poco chiaro allora ha senso creare una lista di tutte le alternative che si hanno a disposizione.
- The mechanical advantage gained by a lever, also known as leverage, serves as the basis of a mental model applicable across a wide variety of situations. The concept can be useful in any situation where applying force or effort in a particular area can produce outsized results, relative to similar applications of force or effort elsewhere.
- certain activities or actions have much greater leverage than others, and spending time or money on these high-leverage activities will produce the greatest effects. Therefore, you should take time to continually identify high-leverage activities. It’s getting more bang for your buck. You can apply this model in all areas of your life. The highest-leverage choice might not be the best fit every time, but the option that provides the most impact at the lowest cost always warrants consideration.
    - Note: Come si può applicare il concetto di leva nella nostra vita di tutti i giorni ed a che tipo di [[mental models\|mental models]] ci permette di arrivare?
      Ci permette di arrivare ad un modello chiamato [[high leverage\|high leverage]] con cui si intende la ricerca, da parte nostra, delle attività e opzioni che più ci possono portare un guadagno rispetto al loro costo, all’atto pratico si tratta di essere opportunisti con le opzioni che abbiamo, si tratta di ricercare il maggiore impatto al minor costo disponibile.
- The Pareto principle can help you find high-leverage activities. It states that in many situations, 80 percent of the results come from approximately 20 percent of the effort. Addressing this 20 percent is therefore a high-leverage activity.
    - Note: Cosa ci può aiutare ad individuare quelle opzioni e situazioni che hanno un [[high leverage\|high leverage]] e quindi maggior impatto ma minor costo?
      Uno de principi che più ci può guidare è quello del [[principio di Pareto\|principio di Pareto]] che afferma come l’80% dei risultati sia spesso prodotto dal 20% degli sforzi. In questo modo per raggiungere le situazioni di high leverage ci basterà trovare quel 20% di sforzo capace di portarci l’80% del risultato.
- This particular 80/20 arrangement of outcomes is known as a power law distribution, where relatively few occurrences account for a significantly outsized proportion of the total.
    - Note: Quale tipo di distribuzione matematica rappresenta al meglio il [[principio di Pareto\|principio di Pareto]] ed indirettamente le situazioni di [[high leverage\|high leverage]] ? La [[power law distribution\|power law distribution]]
- After you determine the 80/20 and address the low-hanging fruit, each additional hour of work will unfortunately produce less and less impactful results. In economics, this model is called the law of diminishing returns. It is the tendency for continued effort to diminish in effectiveness after a certain level of result has been achieved.
    - Note: Cosa accade quando applichiamo il [[principio di Pareto\|principio di Pareto]] e troviamo ed eseguiamo le attività più efficaci per noi, quelle che ci portano più risultati, quelle di [[high leverage\|high leverage]] ?
      Accade che ci ritroviamo in una situazione in cui tutti i nostri futuri sforzi porteranno risultati minori di quelli che abbiamo già raggiunto, tale situazione si definisce come [[law of diminishing returns\|law of diminishing returns]]
- There is a similar concept called the law of diminishing utility, which says that the value, or utility, of consuming an additional item is usually, after a certain point, less than the value of the previous one consumed.
    - Note: Se si passa dal campo dei risultati economici a quello dei risultati in estermini di utilità, quale legge possiamo ottenere simile alla [[law of diminishing returns\|law of diminishing returns]] ? Possiamo ottenere la [[law of diminishing utility\|law of diminishing utility]] che afferma come, dopo aver raggiunto un certo livello di risultati in termini di utilità, tuti quelli che otterremo in seguito saranno minori e meno soddisfacenti.
      In pratica mettiamo l’asticella troppo in alto, la situazione si può portare all’estremo poi quando si passa da una efficacia o utilità ridotte a dei veri e propri risultati negativi.
      In pratica ci si può ritrovare in situazioni in cui si esagera così tanto con gli sforzi, con la ricerca di risultati che ci si ritrova in situazioni in cui otteniamo solo risultati negativi invece che positivi.
- Overdoing it is also a quick path toward burnout, where high stress can take its toll and eventually extinguish your motivation, or worse. In the late 1970s in Japan the term karoshi was coined to describe the increasing number of people, some as young as their twenties and thirties, dying from strokes and heart attacks attributed to overwork.
    - Note: Come mai il [[burnout\|burnout]] può essere inteso come il risultato di una situazione di [[high leverage\|high leverage]] all’opposto?
      Perché è il risultato di situazioni in cui la [[law of diminishing returns\|law of diminishing returns]] è applicata all’estremo negativo, in cui si è nel punto in cui magari invece che i risultati positivi otteniamo solo risultati negativi e quindi spingiamo, spingiamo sempre di più per invertire la rotta: ma questo esige un prezzo e finiamo il carburante.
